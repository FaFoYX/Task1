//
// Created by caoqi on 2018/9/2.
/*
 * 实现Levenberg-Marquardt算法，该算法又称为 damped least squares 阻尼最小二乘，用来求解非线性最小二乘
 * 问题。LM找到的是局部最小值，该算法介于高斯牛顿法和梯度下降法之间，并通过控制信赖域尺寸的大小，在高斯牛顿法
 * 和梯度下降法之间进行调整。LM 算法比高斯牛顿法速度慢但是更为鲁棒，
 *
 * LM算法的原理是用模型函数f对待估向量p在邻域内做线性估计(泰勒展开），忽略掉二阶以上的导数项，从而转化为线性最小
 * 二乘问题。本质上就是用二次曲面对目标函数进行局部近似。LM算法属于一种信赖域法，即：从初始值开始，先假设一个可以
 * 信赖的最大的位移s, 然后以当前点为中心，以s为半径的区域内，通过寻找目标函数的一个近似二次函数的最优点来求得真正
 * 的位移。在得到位移之后，再计算目标函数值，如果其使得目标函数值得下降满足了一定条件，那么说明这个位移是可靠的
 * 则继续按照此规则迭代计算下去；如果其不能使目标函数的下降满足一定的条件，则应该减少信赖域的范围，重新求解。
 *
 * LM算法的一般流程是：
 *       1） 初始化
 *       2） 计算雅阁比矩阵J，构造正规方程(JTJ + lambdaI) = JTf
 *       3） 求解正规方程（共轭梯度或者预定共轭梯度法）
 *       4） 判断若求解成功
 *               增加信赖域(1/lambda)，使得求解算法接近于高斯牛顿法,加快收敛速度
 *               判断终止条件
 *           判断若求解失败
 *               减少信赖域(1/lambda), 使得求解算法解决域梯度下降法
 *       5)  重复1), 2), 3)，4)
 *
 * （注意，信赖域的大小为正规方程中lambda的倒数)
 */
 //
#include <assert.h>
#include <fstream>
#include <sstream>
#include <sfm/camera_pose.h>
#include <iomanip>
#include "sfm/ba_conjugate_gradient.h"
#include "sfm/bundle_adjustment.h"
#include "sfm/ba_sparse_matrix.h"
#include "sfm/ba_dense_vector.h"
#include "sfm/ba_linear_solver.h"
#include "sfm/ba_sparse_matrix.h"
#include "sfm/ba_dense_vector.h"
#include "sfm/ba_cholesky.h"


typedef sfm::ba::SparseMatrix<double> SparseMatrixType;
typedef sfm::ba::DenseVector<double> DenseVectorType;

//global variables
std::vector<sfm::ba::Camera> cameras;
std::vector<sfm::ba::Point3D> points;
std::vector<sfm::ba::Observation> observations;

#define TRUST_REGION_RADIUS_INIT (1000)
#define TRUST_REGION_RADIUS_DECREMENT (1.0 / 10.0)
#define TRUST_REGION_RADIUS_GAIN (10.0)

// lm 算法最多迭代次数
const int lm_max_iterations = 100;
// mean square error
double initial_mse = 0.0;
double final_mse = 0.0;
int num_lm_iterations = 0;
int num_lm_successful_iterations = 0;
int num_lm_unsuccessful_iterations = 0;

// lm 算法终止条件
double lm_mse_threshold = 1e-16;
double lm_delta_threshold = 1e-8;

// 信赖域大小
double trust_region_radius = 1000;
int cg_max_iterations = 1000;
//相机参数个数
int camera_block_dim = 9;

const int num_cam_params = 9;

/**
 * /decription 加载相关数据，包括相机的初始内外参数，三维点，观察点
 * @param file_name
 * @param cams
 * @param pts3D
 * @param observations
 */
void load_data(const std::string& file_name
    , std::vector<sfm::ba::Camera>& cams
    , std::vector<sfm::ba::Point3D>& pts3D
    , std::vector<sfm::ba::Observation>& observations) {

    /* 加载数据 */
    std::ifstream in(file_name);
    assert(in.is_open());
    std::string line, word;

    // 加载相机参数
    {
        int n_cams = 0;
        getline(in, line);
        std::stringstream stream(line);
        stream >> word >> n_cams;
        cams.resize(n_cams);
        for (int i = 0; i < cams.size(); i++) {
            getline(in, line);
            std::stringstream stream(line);
            stream >> cams[i].focal_length;
            stream >> cams[i].distortion[0] >> cams[i].distortion[1];
            for (int j = 0; j < 3; j++)stream >> cams[i].translation[j];
            for (int j = 0; j < 9; j++)stream >> cams[i].rotation[j];
        }
    }

    // 加载三维点
    {
        int n_points = 0;
        getline(in, line);
        std::stringstream stream(line);
        stream >> word >> n_points;
        pts3D.resize(n_points);
        for (int i = 0; i < n_points; i++) {
            getline(in, line);
            std::stringstream stream(line);
            stream >> pts3D[i].pos[0] >> pts3D[i].pos[1] >> pts3D[i].pos[2];
        }
    }

    //加载观察点
    {
        int n_observations = 0;
        getline(in, line);
        std::stringstream stream(line);
        stream >> word >> n_observations;
        observations.resize(n_observations);
        for (int i = 0; i < observations.size(); i++) {
            getline(in, line);
            std::stringstream stream(line);
            stream >> observations[i].camera_id
                >> observations[i].point_id
                >> observations[i].pos[0]
                >> observations[i].pos[1];
        }
    }

}


/*
 * Computes for a given matrix A the square matrix A^T * A for the
 * case that block columns of A only need to be multiplied with itself.
 * Becase the resulting matrix is symmetric, only about half the work
 * needs to be performed.
 */
void matrix_block_column_multiply(sfm::ba::SparseMatrix<double> const& A,
    std::size_t block_size, sfm::ba::SparseMatrix<double>* B)
{
    sfm::ba::SparseMatrix<double>::Triplets triplets;
    triplets.reserve(A.num_cols() * block_size);
    for (std::size_t block = 0; block < A.num_cols(); block += block_size) {
        std::vector<sfm::ba::DenseVector<double>> columns(block_size);
        for (std::size_t col = 0; col < block_size; ++col)
            A.column_nonzeros(block + col, &columns[col]);
        for (std::size_t col = 0; col < block_size; ++col) {
            double dot = columns[col].dot(columns[col]);
            triplets.emplace_back(block + col, block + col, dot);
            for (std::size_t row = col + 1; row < block_size; ++row) {
                dot = columns[col].dot(columns[row]);
                triplets.emplace_back(block + row, block + col, dot);
                triplets.emplace_back(block + col, block + row, dot);
            }
        }
    }
    B->allocate(A.num_cols(), A.num_cols());
    B->set_from_triplets(triplets);
}


/*
 * Inverts a matrix with 3x3 bocks on its diagonal. All other entries
 * must be zero. Reading blocks is thus very efficient.
 */
void
invert_block_matrix_3x3_inplace(sfm::ba::SparseMatrix<double>* A) {
    if (A->num_rows() != A->num_cols())
        throw std::invalid_argument("Block matrix must be square");
    if (A->num_non_zero() != A->num_rows() * 3)
        throw std::invalid_argument("Invalid number of non-zeros");

    for (double* iter = A->begin(); iter != A->end(); )
    {
        double* iter_backup = iter;
        math::Matrix<double, 3, 3> rot;
        for (int i = 0; i < 9; ++i)
            rot[i] = *(iter++);

        double det = math::matrix_determinant(rot);
        if (MATH_DOUBLE_EQ(det, 0.0))
            continue;

        rot = math::matrix_inverse(rot, det);
        iter = iter_backup;
        for (int i = 0; i < 9; ++i)
            *(iter++) = rot[i];
    }
}


/*
     * Inverts a symmetric, positive definite matrix with NxN bocks on its
     * diagonal using Cholesky decomposition. All other entries must be zero.
     */
void
invert_block_matrix_NxN_inplace(sfm::ba::SparseMatrix<double>* A, int blocksize)
{
    if (A->num_rows() != A->num_cols())
        throw std::invalid_argument("Block matrix must be square");
    if (A->num_non_zero() != A->num_rows() * blocksize)
        throw std::invalid_argument("Invalid number of non-zeros");

    int const bs2 = blocksize * blocksize;
    std::vector<double> matrix_block(bs2);
    for (double* iter = A->begin(); iter != A->end(); )
    {
        double* iter_backup = iter;
        for (int i = 0; i < bs2; ++i)
            matrix_block[i] = *(iter++);

        sfm::ba::cholesky_invert_inplace(matrix_block.data(), blocksize);

        iter = iter_backup;
        for (int i = 0; i < bs2; ++i)
            if (std::isfinite(matrix_block[i]))
                *(iter++) = matrix_block[i];
            else
                *(iter++) = 0.0;
    }
}

/**
 * /descrition 将角轴法转化成旋转矩阵
 * @param r 角轴向量
 * @param m 旋转矩阵
 */
void rodrigues_to_matrix(double const* r, double* m)
{
    /* Obtain angle from vector length. */
    double a = std::sqrt(r[0] * r[0] + r[1] * r[1] + r[2] * r[2]);
    /* Precompute sine and cosine terms. */
    double ct = (a == 0.0) ? 0.5f : (1.0f - std::cos(a)) / (2.0 * a);
    double st = (a == 0.0) ? 1.0 : std::sin(a) / a;
    /* R = I + st * K + ct * K^2 (with cross product matrix K). */
    m[0] = 1.0 - (r[1] * r[1] + r[2] * r[2]) * ct;
    m[1] = r[0] * r[1] * ct - r[2] * st;
    m[2] = r[2] * r[0] * ct + r[1] * st;
    m[3] = r[0] * r[1] * ct + r[2] * st;
    m[4] = 1.0f - (r[2] * r[2] + r[0] * r[0]) * ct;
    m[5] = r[1] * r[2] * ct - r[0] * st;
    m[6] = r[2] * r[0] * ct - r[1] * st;
    m[7] = r[1] * r[2] * ct + r[0] * st;
    m[8] = 1.0 - (r[0] * r[0] + r[1] * r[1]) * ct;
}

/**
 * \description 根据求解得到的增量，对相机参数进行更新
 * @param cam
 * @param update
 * @param out
 */
void update_camera(sfm::ba::Camera const& cam,
    double const* update, sfm::ba::Camera* out)
{
    out->focal_length = cam.focal_length + update[0];
    out->distortion[0] = cam.distortion[0] + update[1];
    out->distortion[1] = cam.distortion[1] + update[2];

    out->translation[0] = cam.translation[0] + update[3];
    out->translation[1] = cam.translation[1] + update[4];
    out->translation[2] = cam.translation[2] + update[5];

    double rot_orig[9];
    std::copy(cam.rotation, cam.rotation + 9, rot_orig);
    double rot_update[9];
    rodrigues_to_matrix(update + 6, rot_update);
    math::matrix_multiply(rot_update, 3, 3, rot_orig, 3, out->rotation);
}

/**
 * \description 根据求解的增量，对三维点坐标进行更新
 * @param pt
 * @param update
 * @param out
 */
void update_point(sfm::ba::Point3D const& pt,
    double const* update, sfm::ba::Point3D* out)
{
    out->pos[0] = pt.pos[0] + update[0];
    out->pos[1] = pt.pos[1] + update[1];
    out->pos[2] = pt.pos[2] + update[2];
}

/**
 * /descripition 根据求得的delta_x, 更新相机参数和三维点
 * @param delta_x
 * @param cameras
 * @param points
 */
void
update_parameters(DenseVectorType const& delta_x
    , std::vector<sfm::ba::Camera>* cameras
    , std::vector<sfm::ba::Point3D>* points)
{
    /* Update cameras. */
    std::size_t total_camera_params = 0;
    for (std::size_t i = 0; i < cameras->size(); ++i) {
        update_camera(cameras->at(i),
            delta_x.data() + num_cam_params * i,
            &cameras->at(i));
        total_camera_params = cameras->size() * num_cam_params;
    }

    /* Update points. */
    for (std::size_t i = 0; i < points->size(); ++i) {
        update_point(points->at(i),
            delta_x.data() + total_camera_params + i * 3,
            &points->at(i));
    }
}

/**
 * \description 对像素进行径向畸变
 * @param x
 * @param y
 * @param dist
 */
void radial_distort(double* x, double* y, double const* dist)
{
    double const radius2 = *x * *x + *y * *y;
    double const factor = 1.0 + radius2 * (dist[0] + dist[1] * radius2);
    *x *= factor;
    *y *= factor;
}

/**
 * \description 计算重投影误差
 * @param vector_f
 * @param delta_x
 * @param cameras
 * @param points
 * @param observations
 */
void compute_reprojection_errors(DenseVectorType* vector_f
    , DenseVectorType const* delta_x
    , std::vector<sfm::ba::Camera>* cameras
    , std::vector<sfm::ba::Point3D>* points
    , std::vector<sfm::ba::Observation>* observations)
{
    if (vector_f->size() != observations->size() * 2)
        vector_f->resize(observations->size() * 2);

#pragma omp parallel for
    for (std::size_t i = 0; i < observations->size(); ++i)
    {
        sfm::ba::Observation const& obs = observations->at(i);
        sfm::ba::Point3D const& p3d = points->at(obs.point_id);
        sfm::ba::Camera const& cam = cameras->at(obs.camera_id);

        double const* flen = &cam.focal_length; // 相机焦距
        double const* dist = cam.distortion;    // 径向畸变系数
        double const* rot = cam.rotation;       // 相机旋转矩阵
        double const* trans = cam.translation;  // 相机平移向量
        double const* point = p3d.pos;          // 三维点坐标

        sfm::ba::Point3D new_point;
        sfm::ba::Camera new_camera;

        // 如果delta_x 不为空，则先利用delta_x对相机和结构进行更新，然后再计算重投影误差
        if (delta_x != nullptr)
        {
            std::size_t cam_id = obs.camera_id * num_cam_params;
            std::size_t pt_id = obs.point_id * 3;


            update_camera(cam, delta_x->data() + cam_id, &new_camera);
            flen = &new_camera.focal_length;
            dist = new_camera.distortion;
            rot = new_camera.rotation;
            trans = new_camera.translation;
            pt_id += cameras->size() * num_cam_params;


            update_point(p3d, delta_x->data() + pt_id, &new_point);
            point = new_point.pos;
        }

        /* Project point onto image plane. */
        double rp[] = { 0.0, 0.0, 0.0 };
        for (int d = 0; d < 3; ++d)
        {
            rp[0] += rot[0 + d] * point[d];
            rp[1] += rot[3 + d] * point[d];
            rp[2] += rot[6 + d] * point[d];
        }
        rp[2] = (rp[2] + trans[2]);
        rp[0] = (rp[0] + trans[0]) / rp[2];
        rp[1] = (rp[1] + trans[1]) / rp[2];

        /* Distort reprojections. */
        radial_distort(rp + 0, rp + 1, dist);

        /* Compute reprojection error. */
        vector_f->at(i * 2 + 0) = rp[0] * (*flen) - obs.pos[0];
        vector_f->at(i * 2 + 1) = rp[1] * (*flen) - obs.pos[1];
    }
}

/**
 * \description 计算均方误差
 * @param vector_f
 * @return
 */
double compute_mse(DenseVectorType const& vector_f) {
    double mse = 0.0;
    for (std::size_t i = 0; i < vector_f.size(); ++i)
        mse += vector_f[i] * vector_f[i];
    return mse / static_cast<double>(vector_f.size() / 2);
}

/**
 * /description 计算观察点坐标(x,y)，相遇对相机参数和三维点坐标的雅阁比矩阵
 * @param cam
 * @param point
 * @param cam_x_ptr
 * @param cam_y_ptr
 * @param point_x_ptr
 * @param point_y_ptr
 */
void my_jacobian(sfm::ba::Camera const& cam,
    sfm::ba::Point3D const& point,
    double* cam_x_ptr, double* cam_y_ptr,
    double* point_x_ptr, double* point_y_ptr)
{
    const double f = cam.focal_length;
    const double* R = cam.rotation;
    const double* t = cam.translation;
    const double* X = point.pos;
    const double k0 = cam.distortion[0];
    const double k1 = cam.distortion[1];

    const double xc = R[0] * X[0] + R[1] * X[1] + R[2] * X[2] + t[0];
    const double yc = R[3] * X[0] + R[4] * X[1] + R[5] * X[2] + t[1];
    const double zc = R[6] * X[0] + R[7] * X[1] + R[8] * X[2] + t[2];

    const double x = xc / zc;
    const double y = yc / zc;

    const double r2 = x * x + y * y;
    const double distort = 1.0 + (k0 + k1 * r2) * r2;

    const double u = f * distort * x;
    const double v = f * distort * y;

    /*关于焦距的偏导数*/
    cam_x_ptr[0] = distort * x;
    cam_y_ptr[0] = distort * y;


    /*计算关于径向畸变函数k0, k1的偏导数*/
    // 计算中间变量
    const double u_deriv_distort = f * x;
    const double v_deriv_distort = f * y;
    const double distort_deriv_k0 = r2;
    const double distort_deriv_k1 = r2 * r2;

    cam_x_ptr[1] = u_deriv_distort * distort_deriv_k0;
    cam_x_ptr[2] = u_deriv_distort * distort_deriv_k1;

    cam_y_ptr[1] = v_deriv_distort * distort_deriv_k0;
    cam_y_ptr[2] = v_deriv_distort * distort_deriv_k1;


    // 计算中间变量 (x,y)关于(xc, yc, zc)的偏导数
    const double x_deriv_xc = 1 / zc; const double x_deriv_yc = 0;    const double x_deriv_zc = -x / zc;
    const double y_deriv_xc = 0; const double y_deriv_yc = 1 / zc; const double y_deriv_zc = -y / zc;

    // 计算u, v关于x, y的偏导数
    const double u_deriv_x = f * distort;
    const double v_deriv_y = f * distort;

    // 计算中间变量distort关于r2的偏导数
    const double distort_deriv_r2 = k0 + 2 * k1 * r2;

    // 计算中间变量r2关于xc, yc, zc的偏导数
    const double r2_deriv_xc = 2 * x / zc;
    const double r2_deriv_yc = 2 * y / zc;
    const double r2_deriv_zc = -2 * r2 / zc;

    // 计算中间变量distort关于xc, yc, zc的偏导数
    const double distort_deriv_xc = distort_deriv_r2 * r2_deriv_xc;
    const double distort_deriv_yc = distort_deriv_r2 * r2_deriv_yc;
    const double distort_deriv_zc = distort_deriv_r2 * r2_deriv_zc;

    // 计算(u,v)关于xc, yc, zc的偏导数
    const double u_deriv_xc = u_deriv_distort * distort_deriv_xc + u_deriv_x * x_deriv_xc;
    const double u_deriv_yc = u_deriv_distort * distort_deriv_yc + u_deriv_x * x_deriv_yc;
    const double u_deriv_zc = u_deriv_distort * distort_deriv_zc + u_deriv_x * x_deriv_zc;

    const double v_deriv_xc = v_deriv_distort * distort_deriv_xc + v_deriv_y * y_deriv_xc;
    const double v_deriv_yc = v_deriv_distort * distort_deriv_yc + v_deriv_y * y_deriv_yc;
    const double v_deriv_zc = v_deriv_distort * distort_deriv_zc + v_deriv_y * y_deriv_zc;

    /* 计算关于平移向量的t0, t1, t2的偏导数*/
    const double xc_deriv_t0 = 1;
    const double yc_deriv_t1 = 1;
    const double zc_deriv_t2 = 1;

    cam_x_ptr[3] = u_deriv_xc * xc_deriv_t0;
    cam_x_ptr[4] = u_deriv_yc * yc_deriv_t1;
    cam_x_ptr[5] = u_deriv_zc * zc_deriv_t2;

    cam_y_ptr[3] = v_deriv_xc * xc_deriv_t0;
    cam_y_ptr[4] = v_deriv_yc * yc_deriv_t1;
    cam_y_ptr[5] = v_deriv_zc * zc_deriv_t2;


    /* 计算关于旋转矩阵(表示为角轴向量w0, w1, w2)的偏导数 */
    const double rx = R[0] * X[0] + R[1] * X[1] + R[2] * X[2];
    const double ry = R[3] * X[0] + R[4] * X[1] + R[5] * X[2];
    const double rz = R[6] * X[0] + R[7] * X[1] + R[8] * X[2];
    const double xc_deriv_w0 = 0;   const double xc_deriv_w1 = rz; const double xc_deriv_w2 = -ry;
    const double yc_deriv_w0 = -rz; const double yc_deriv_w1 = 0; const double yc_deriv_w2 = rx;
    const double zc_deriv_w0 = ry;  const double zc_deriv_w1 = -rx; const double zc_deriv_w2 = 0;

    cam_x_ptr[6] = u_deriv_yc * yc_deriv_w0 + u_deriv_zc * zc_deriv_w0;
    cam_x_ptr[7] = u_deriv_xc * xc_deriv_w1 + u_deriv_zc * zc_deriv_w1;
    cam_x_ptr[8] = u_deriv_xc * xc_deriv_w2 + u_deriv_yc * yc_deriv_w2;

    cam_y_ptr[6] = v_deriv_yc * yc_deriv_w0 + v_deriv_zc * zc_deriv_w0;
    cam_y_ptr[7] = v_deriv_xc * xc_deriv_w1 + v_deriv_zc * zc_deriv_w1;
    cam_y_ptr[8] = v_deriv_xc * xc_deriv_w2 + v_deriv_yc * yc_deriv_w2;


    /* 计算关于三维点坐标X,Y,X的偏导数*/
    const double xc_deriv_X = R[0]; const double xc_deriv_Y = R[1]; const double xc_deriv_Z = R[2];
    const double yc_deriv_X = R[3]; const double yc_deriv_Y = R[4]; const double yc_deriv_Z = R[5];
    const double zc_deriv_X = R[6]; const double zc_deriv_Y = R[7]; const double zc_deriv_Z = R[8];

    point_x_ptr[0] = u_deriv_xc * xc_deriv_X + u_deriv_yc * yc_deriv_X + u_deriv_zc * zc_deriv_X;
    point_x_ptr[1] = u_deriv_xc * xc_deriv_Y + u_deriv_yc * yc_deriv_Y + u_deriv_zc * zc_deriv_Y;
    point_x_ptr[2] = u_deriv_xc * xc_deriv_Z + u_deriv_yc * yc_deriv_Z + u_deriv_zc * zc_deriv_Z;

    point_y_ptr[0] = v_deriv_xc * xc_deriv_X + v_deriv_yc * yc_deriv_X + v_deriv_zc * zc_deriv_X;
    point_y_ptr[1] = v_deriv_xc * xc_deriv_Y + v_deriv_yc * yc_deriv_Y + v_deriv_zc * zc_deriv_Y;
    point_y_ptr[2] = v_deriv_xc * xc_deriv_Z + v_deriv_yc * yc_deriv_Z + v_deriv_zc * zc_deriv_Z;

}

/**
 * \description 构造雅阁比矩阵，采用稀疏矩阵形式，
 *       关于相机参数的雅阁比矩阵大小为：(2*observations.size()) x (num_cameras*9)
 *       关于三维点坐标的雅阁比矩阵大小为：(2*observation.size()) x (num_points*3)
 * @param jac_cam-- 观察点相对于相机参数的雅阁比矩阵
 * @param jac_points--观察点相对于三维点的雅阁比矩阵
 */
void analytic_jacobian(SparseMatrixType* jac_cam
    , SparseMatrixType* jac_points) {
    assert(jac_cam);
    assert(jac_points);
    // 相机和三维点jacobian矩阵的行数都是n_observations*2
    // 相机jacobian矩阵jac_cam的列数是n_cameras* n_cam_params
    // 三维点jacobian矩阵jac_points的列数是n_points*3
    std::size_t const camera_cols = cameras.size() * num_cam_params;
    std::size_t const point_cols = points.size() * 3;
    std::size_t const jacobi_rows = observations.size() * 2;

    // 定义稀疏矩阵的基本元素
    SparseMatrixType::Triplets cam_triplets, point_triplets;
    cam_triplets.reserve(observations.size() * 2 * num_cam_params);
    point_triplets.reserve(observations.size() * 2 * 3);


    double cam_x_ptr[9], cam_y_ptr[9], point_x_ptr[3], point_y_ptr[3];
    // 对于每一个观察到的二维点
    for (std::size_t i = 0; i < observations.size(); ++i) {

        // 获取二维点，obs.point_id 三维点的索引，obs.camera_id 相机的索引
        sfm::ba::Observation const& obs = observations[i];
        // 三维点坐标
        sfm::ba::Point3D const& p3d = points[obs.point_id];
        // 相机参数
        sfm::ba::Camera const& cam = cameras[obs.camera_id];

        /*对一个三维点和相机求解偏导数*/
        my_jacobian(cam, p3d,
            cam_x_ptr, cam_y_ptr, point_x_ptr, point_y_ptr);

        /*观察点对应雅各比矩阵的行，第i个观察点在雅各比矩阵的位置是2*i, 2*i+1*/
        std::size_t row_x = i * 2 + 0;
        std::size_t row_y = i * 2 + 1;

        /*jac_cam中相机对应的列数为camera_id* n_cam_params*/
        std::size_t cam_col = obs.camera_id * num_cam_params;

        /*jac_points中三维点对应的列数为point_id* 3*/
        std::size_t point_col = obs.point_id * 3;

        for (int j = 0; j < num_cam_params; ++j) {
            cam_triplets.push_back(SparseMatrixType::Triplet(row_x, cam_col + j, cam_x_ptr[j]));
            cam_triplets.push_back(SparseMatrixType::Triplet(row_y, cam_col + j, cam_y_ptr[j]));
        }

        for (int j = 0; j < 3; ++j) {
            point_triplets.push_back(SparseMatrixType::Triplet(row_x, point_col + j, point_x_ptr[j]));
            point_triplets.push_back(SparseMatrixType::Triplet(row_y, point_col + j, point_y_ptr[j]));
        }
    }


    if (jac_cam != nullptr) {
        jac_cam->allocate(jacobi_rows, camera_cols);
        jac_cam->set_from_triplets(cam_triplets);
    }

    if (jac_points != nullptr) {
        jac_points->allocate(jacobi_rows, point_cols);
        jac_points->set_from_triplets(point_triplets);
    }
}



sfm::ba::LinearSolver::Status my_solve_schur(
    SparseMatrixType const& jac_cams,
    SparseMatrixType const& jac_points,
    DenseVectorType const& values,
    DenseVectorType* delta_x) {
    /*
     *   雅阁比矩阵：
     *           J = [Jc Jp]
     *   Jc是与相机相关的模块，Jp是与三维点相关的模块。
     *   正规方程
     *          (J^TJ + lambda*I)delta_x = J^T(x - F)
     *   进一步写为
     *   [ Jcc+ lambda*Icc   Jcp            ][delta_c]= [v]
     *   [ Jxp               Jpp+lambda*Ipp ][delta_p]  [w]
     *
     *   B = Jcc, E = Jcp, C = Jpp
     *  其中 Jcc = Jc^T* Jc, Jcx = Jc^T*Jx, Jxc = Jx^TJc, Jxx = Jx^T*Jx
     *      v = Jc^T(F-x), w = Jx^T(F-x), deta_x = [delta_c; delta_p]
     */

     // 误差向量
    DenseVectorType const& F = values;
    // 关于相机的雅阁比矩阵
    SparseMatrixType const& Jc = jac_cams;
    // 关于三维点的雅阁比矩阵
    SparseMatrixType const& Jp = jac_points;
    SparseMatrixType JcT = Jc.transpose();
    SparseMatrixType JpT = Jp.transpose();

    // 构造正规方程
    SparseMatrixType B, C;
    // B = Jc^T* Jc
    matrix_block_column_multiply(Jc, camera_block_dim, &B);
    // C = Jp^T*Jp
    matrix_block_column_multiply(Jp, 3, &C);
    // E = Jc^T*Jp
    SparseMatrixType E = JcT.multiply(Jp);

    /* Assemble two values vectors. */
    DenseVectorType v = JcT.multiply(F);
    DenseVectorType w = JpT.multiply(F);
    v.negate_self();
    w.negate_self();

    /* 以矩阵B和C的对角元素重新构建对角阵*/
    //    SparseMatrixType B_diag = B.diagonal_matrix();
    //    SparseMatrixType C_diag = C.diagonal_matrix();

    /* 添加信赖域 */
    C.mult_diagonal(1.0 + 1.0 / trust_region_radius);
    B.mult_diagonal(1.0 + 1.0 / trust_region_radius);

    /* 求解C矩阵的逆C = inv(Jx^T+Jx + lambda*Ixx)*/
    invert_block_matrix_3x3_inplace(&C);

    /* 计算S矩阵的Schur补用于高斯消元. */
    SparseMatrixType ET = E.transpose();

    // S = (Jcc+lambda*Icc) - Jc^T*Jx*inv(Jxx+ lambda*Ixx)*Jx^T*Jc
    SparseMatrixType S = B.subtract(E.multiply(C).multiply(ET));
    // rhs = v -  Jc^T*Jx*inv(Jxx+ lambda*Ixx)*w
    DenseVectorType rhs = v.subtract(E.multiply(C.multiply(w)));

    /* Compute pre-conditioner for linear system. */
    //SparseMatrixType precond = S.diagonal_matrix();
    //precond.cwise_invert();
    SparseMatrixType precond = B;
    invert_block_matrix_NxN_inplace(&precond, camera_block_dim);

    /* 用共轭梯度法求解相机参数. */
    DenseVectorType delta_y(Jc.num_cols());
    typedef sfm::ba::ConjugateGradient<double> CGSolver;
    CGSolver::Options cg_opts;
    cg_opts.max_iterations = cg_max_iterations;
    cg_opts.tolerance = 1e-20;
    CGSolver solver(cg_opts);
    CGSolver::Status cg_status;
    cg_status = solver.solve(S, rhs, &delta_y, &precond);

    sfm::ba::LinearSolver::Status status;
    status.num_cg_iterations = cg_status.num_iterations;
    switch (cg_status.info) {
    case CGSolver::CG_CONVERGENCE:
        status.success = true;
        break;
    case CGSolver::CG_MAX_ITERATIONS:
        status.success = true;
        break;
    case CGSolver::CG_INVALID_INPUT:
        std::cout << "BA: CG failed (invalid input)" << std::endl;
        status.success = false;
        return status;
    default:
        break;
    }

    /* 将相机参数带入到第二个方程中，求解三维点的参数. */
    /*E= inv(Jp^T Jp) (JpT.multiply(F)-Jc^T * Jp * delta_y)*/
    DenseVectorType delta_z = C.multiply(w.subtract(ET.multiply(delta_y)));

    /* Fill output vector. */
    std::size_t const jac_cam_cols = Jc.num_cols();
    std::size_t const jac_point_cols = Jp.num_cols();
    std::size_t const jac_cols = jac_cam_cols + jac_point_cols;

    if (delta_x->size() != jac_cols)
        delta_x->resize(jac_cols, 0.0);
    for (std::size_t i = 0; i < jac_cam_cols; ++i)
        delta_x->at(i) = delta_y[i];
    for (std::size_t i = 0; i < jac_point_cols; ++i)
        delta_x->at(jac_cam_cols + i) = delta_z[i];

    return status;
}
/**
 * /description  LM 算法流程
 * @param cameras
 * @param points
 * @param observations
 */
void lm_optimization(std::vector<sfm::ba::Camera>* cameras
    , std::vector<sfm::ba::Point3D>* points
    , std::vector<sfm::ba::Observation>* observations) {



    /*1.0 初始化*/
    // 计算重投影误差向量
    DenseVectorType F, F_new;
    compute_reprojection_errors(&F, nullptr, cameras, points, observations);// todo F 是误差向量
    // 计算初始的均方误差
    double current_mse = compute_mse(F);
    initial_mse = current_mse;
    final_mse = current_mse;


    // 设置共轭梯度法的相关参数
    trust_region_radius = TRUST_REGION_RADIUS_INIT;

    /* Levenberg-Marquard 算法. */
    for (int lm_iter = 0; ; ++lm_iter) {

        // 判断终止条件，均方误差小于一定阈值
        if (current_mse < lm_mse_threshold) {
            std::cout << "BA: Satisfied MSE threshold." << std::endl;
            break;
        }

        //1.0 计算雅阁比矩阵
        SparseMatrixType Jc, Jp;
        analytic_jacobian(&Jc, &Jp);

        //2.0 预置共轭梯梯度法对正规方程进行求解*/
        DenseVectorType delta_x;
        sfm::ba::LinearSolver::Status cg_status = my_solve_schur(Jc, Jp, F, &delta_x);

        //3.0 根据计算得到的偏移量，重新计算冲投影误差和均方误差，用于判断终止条件和更新条件.
        double new_mse, delta_mse, delta_mse_ratio = 1.0;

        // 正规方程求解成功的情况下
        if (cg_status.success) {
            /*重新计算相机和三维点，计算重投影误差，注意原始的相机参数没有被更新*/
            compute_reprojection_errors(&F_new, &delta_x, cameras, points, observations);
            /* 计算新的残差值 */
            new_mse = compute_mse(F_new);
            /* 均方误差的绝对变化值和相对变化率*/
            delta_mse = current_mse - new_mse;
            delta_mse_ratio = 1.0 - new_mse / current_mse;
        }
        // 正规方程求解失败的情况下
        else {
            new_mse = current_mse;
            delta_mse = 0.0;
        }

        // new_mse < current_mse表示残差值减少
        bool successful_iteration = delta_mse > 0.0;

        /*
         * 如果正规方程求解成功，则更新相机参数和三维点坐标，并且增大信赖域的尺寸，使得求解方式
         * 趋近于高斯牛顿法
         */
        if (successful_iteration) {
            std::cout << "BA: #" << std::setw(2) << std::left << lm_iter
                << " success" << std::right
                << ", MSE " << std::setw(11) << current_mse
                << " -> " << std::setw(11) << new_mse
                << ", CG " << std::setw(3) << cg_status.num_cg_iterations
                << ", TRR " << trust_region_radius
                << ", MSE Ratio: " << delta_mse_ratio
                << std::endl;

            num_lm_iterations += 1;
            num_lm_successful_iterations += 1;

            /* 对相机参数和三点坐标进行更新 */
            update_parameters(delta_x, cameras, points);

            std::swap(F, F_new);
            current_mse = new_mse;

            if (delta_mse_ratio < lm_delta_threshold) {
                std::cout << "BA: Satisfied delta mse ratio threshold of "
                    << lm_delta_threshold << std::endl;
                break;
            }

            // 增大信赖域大小
            trust_region_radius *= TRUST_REGION_RADIUS_GAIN;
        }
        else {
            std::cout << "BA: #" << std::setw(2) << std::left << lm_iter
                << " failure" << std::right
                << ", MSE " << std::setw(11) << current_mse
                << ",    " << std::setw(11) << " "
                << " CG " << std::setw(3) << cg_status.num_cg_iterations
                << ", TRR " << trust_region_radius
                << std::endl;

            num_lm_iterations += 1;
            num_lm_unsuccessful_iterations += 1;
            // 求解失败的减小信赖域尺寸
            trust_region_radius *= TRUST_REGION_RADIUS_DECREMENT;
        }

        /* 判断是否超过最大的迭代次数. */
        if (lm_iter + 1 >= lm_max_iterations) {
            std::cout << "BA: Reached maximum LM iterations of "
                << lm_max_iterations << std::endl;
            break;
        }
    }

    final_mse = current_mse;
}

int main23(int argc, char* argv[])
{

    /* 加载数据 */
    load_data("./examples/task2/test_ba.txt", cameras, points, observations);

    lm_optimization(&cameras, &points, &observations);

    // ba优化
    /*
    sfm::ba::BundleAdjustment::Options ba_opts;
    ba_opts.verbose_output = true;
    ba_opts.lm_mse_threshold = 1e-16;
    ba_opts.lm_delta_threshold = 1e-8;
    sfm::ba::BundleAdjustment ba(ba_opts);
    ba.set_cameras(&cameras);
    ba.set_points(&points);
    ba.set_observations(&observations);
    ba.optimize();
    ba.print_status();
    */

    // 将优化后的结果重新赋值
    std::vector<sfm::CameraPose> new_cam_poses(2);
    std::vector<math::Vec2f> radial_distortion(2);
    std::vector<math::Vec3f> new_pts_3d(points.size());
    for (int i = 0; i < cameras.size(); i++) {
        std::copy(cameras[i].translation, cameras[i].translation + 3, new_cam_poses[i].t.begin());
        std::copy(cameras[i].rotation, cameras[i].rotation + 9, new_cam_poses[i].R.begin());
        radial_distortion[i] = math::Vec2f(cameras[i].distortion[0], cameras[i].distortion[1]);
        new_cam_poses[i].set_k_matrix(cameras[i].focal_length, 0.0, 0.0);
    }
    for (int i = 0; i < new_pts_3d.size(); i++) {
        std::copy(points[i].pos, points[i].pos + 3, new_pts_3d[i].begin());
    }

    // 输出优化信息
    std::cout << "Params after BA: " << std::endl;
    std::cout << "  f: " << new_cam_poses[0].get_focal_length() << std::endl;
    std::cout << "  distortion: " << radial_distortion[0][0] << ", " << radial_distortion[0][1] << std::endl;
    std::cout << "  R: " << new_cam_poses[0].R << std::endl;
    std::cout << "  t: " << new_cam_poses[0].t << std::endl;

    // 输出优化信息
    std::cout << "Params after BA: " << std::endl;
    std::cout << "  f: " << new_cam_poses[1].get_focal_length() << std::endl;
    std::cout << "  distortion: " << radial_distortion[1][0] << ", " << radial_distortion[1][1] << std::endl;
    std::cout << "  R: " << new_cam_poses[1].R << std::endl;
    std::cout << "  t: " << new_cam_poses[1].t << std::endl;


    std::cout << "points 3d: " << std::endl;
    for (int i = 0; i < points.size(); i++) {
        std::cout << points[i].pos[0] << ", " << points[i].pos[1] << ", " << points[i].pos[2] << std::endl;
    }

    //    Params after BA:
    //    f: 0.919446
    //    distortion: -0.108421, 0.103782
    //    R: 0.999999 -0.00068734 -0.00135363
    //    0.000675175 0.999952 -0.0104268
    //    0.0013597 0.0104261 0.999952
    //    t: 0.00276221 0.0588868 -0.128463

    //    Params after BA:
    //    f: 0.920023
    //    distortion: -0.106701, 0.104344
    //    R: 0.999796 -0.0127484 0.0156791
    //    0.0128673 0.999897 -0.00735337
    //              -0.0155827 0.00755345 0.999857
    //    t: 0.0814124 0.93742 -0.0895658

    //    points 3d:
    //    1.36957, -1.17132, 7.04854
    //    0.0225931, 0.978747, 7.48085


    return 0;
}